import streamlit as st
import pandas as pd
import numpy as np
import folium
import streamlit.components.v1 as components

# ====================================================================
# --- 1. í—¬í¼ í•¨ìˆ˜ ì •ì˜ (ë°ì´í„° ë¡œë“œ ë° ê±°ë¦¬ ê³„ì‚°) ---
# ====================================================================

@st.cache_data(show_spinner="ì¸í”„ë¼ ë°ì´í„° í†µí•© ë¡œë“œ ì¤‘...")
def load_all_infrastructure_data():
    all_data = []
    debug_info = [] 
    
    def read_csv_safe(file_path):
        encodings = ['utf-8', 'cp949', 'euc-kr']
        for enc in encodings:
            try:
                return pd.read_csv(file_path, encoding=enc)
            except UnicodeDecodeError:
                continue
        raise ValueError(f"âŒ '{file_path}' íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    # 1. í•™êµ
    try:
        df_school = read_csv_safe("school.csv")
        df_school = df_school.rename(columns={'school_name': 'infra_name'})
        all_data.append(df_school[['type', 'infra_name', 'lat', 'lng']])
        debug_info.append(f"âœ… í•™êµ: {len(df_school)}ê°œ ë¡œë“œ")
    except: debug_info.append("âŒ í•™êµ íŒŒì¼ ì—†ìŒ/ì˜¤ë¥˜")
        
    # 2. ë¬¸í™”ì‹œì„¤
    try:
        df_art = read_csv_safe("art.csv")
        df_art['type'] = 'ë¬¸í™”ì‹œì„¤'
        df_art = df_art.rename(columns={'ë¬¸í™”ì‹œì„¤ëª…': 'infra_name'})
        all_data.append(df_art[['type', 'infra_name', 'lat', 'lng']])
        debug_info.append(f"âœ… ë¬¸í™”ì‹œì„¤: {len(df_art)}ê°œ ë¡œë“œ")
    except: debug_info.append("âŒ ë¬¸í™”ì‹œì„¤ íŒŒì¼ ì—†ìŒ/ì˜¤ë¥˜")

    # 3. ë³‘ì› (ëŒ€í˜•/ì¼ë°˜ ë¶„ë¥˜ ë¡œì§ í¬í•¨)
    try:
        df_hospital = read_csv_safe("hospital.csv")
        def classify_hospital(row):
            val = str(row.get('ì‘ê¸‰ì˜ë£Œê¸°ê´€ì½”ë“œëª…', ''))
            if 'ì‘ê¸‰' in val and 'ì´ì™¸' not in val: return 'ëŒ€í˜•ë³‘ì›'
            if row.get('ì‘ê¸‰ì‹¤ìš´ì˜ì—¬ë¶€(1/2)') == 1: return 'ëŒ€í˜•ë³‘ì›'
            return 'ì¼ë°˜ë³‘ì›' 

        df_hospital['type'] = df_hospital.apply(classify_hospital, axis=1)
        if 'ê¸°ê´€ëª…' in df_hospital.columns:
            df_hospital = df_hospital.rename(columns={'ê¸°ê´€ëª…': 'infra_name'})
            all_data.append(df_hospital[['type', 'infra_name', 'lat', 'lng']])
            debug_info.append(f"âœ… ë³‘ì›: {len(df_hospital)}ê°œ ë¡œë“œ")
    except: debug_info.append("âŒ ë³‘ì› íŒŒì¼ ì—†ìŒ/ì˜¤ë¥˜")

    # 4. ê³µì›
    try:
        df_park = read_csv_safe("park.csv")
        df_park['type'] = 'ê³µì›'
        df_park = df_park.rename(columns={'ê³µì›ëª…': 'infra_name'})
        all_data.append(df_park[['type', 'infra_name', 'lat', 'lng']])
        debug_info.append(f"âœ… ê³µì›: {len(df_park)}ê°œ ë¡œë“œ")
    except: debug_info.append("âŒ ê³µì› íŒŒì¼ ì—†ìŒ/ì˜¤ë¥˜")

    # 5. ë²„ìŠ¤ì •ë¥˜ì¥
    try:
        df_bus = read_csv_safe("bus_stop.csv")
        df_bus['type'] = 'ë²„ìŠ¤ì •ë¥˜ì¥'
        df_bus = df_bus.rename(columns={'name': 'infra_name'})
        all_data.append(df_bus[['type', 'infra_name', 'lat', 'lng']])
        debug_info.append(f"âœ… ë²„ìŠ¤ì •ë¥˜ì¥: {len(df_bus)}ê°œ ë¡œë“œ")
    except: debug_info.append("âŒ ë²„ìŠ¤ì •ë¥˜ì¥ íŒŒì¼ ì—†ìŒ/ì˜¤ë¥˜")

    # 6. ì§€í•˜ì² ì—­
    try:
        df_subway = read_csv_safe("subway.csv")
        df_subway['type'] = 'ì§€í•˜ì² ì—­'
        if 'name' in df_subway.columns: df_subway = df_subway.rename(columns={'name': 'infra_name'})
        elif 'ì—­ì‚¬ëª…' in df_subway.columns: df_subway = df_subway.rename(columns={'ì—­ì‚¬ëª…': 'infra_name'})
        all_data.append(df_subway[['type', 'infra_name', 'lat', 'lng']])
        debug_info.append(f"âœ… ì§€í•˜ì² ì—­: {len(df_subway)}ê°œ ë¡œë“œ")
    except: debug_info.append("âŒ ì§€í•˜ì² ì—­ íŒŒì¼ ì—†ìŒ/ì˜¤ë¥˜")

    # 7. ëŒ€í˜•ë§ˆíŠ¸
    try:
        df_market = read_csv_safe("big_market.csv")
        df_market['type'] = df_market.get('ì—…íƒœêµ¬ë¶„ëª…', 'ëŒ€í˜•ë§ˆíŠ¸')
        df_market = df_market.rename(columns={'ì‚¬ì—…ì¥ëª…': 'infra_name'})
        all_data.append(df_market[['type', 'infra_name', 'lat', 'lng']])
        debug_info.append(f"âœ… ëŒ€í˜•ë§ˆíŠ¸: {len(df_market)}ê°œ ë¡œë“œ")
    except: debug_info.append("âŒ ëŒ€í˜•ë§ˆíŠ¸ íŒŒì¼ ì—†ìŒ/ì˜¤ë¥˜")

    # 8. ì²´ìœ¡ì‹œì„¤
    try:
        df_gym = read_csv_safe("gym.csv")
        df_gym = df_gym.rename(columns={'name': 'infra_name', 'ìœ„ë„': 'lat', 'ê²½ë„': 'lng'})
        df_gym['type'] = df_gym['type'].fillna('ê¸°íƒ€')
        all_data.append(df_gym[['type', 'infra_name', 'lat', 'lng']])
        debug_info.append(f"âœ… ì²´ìœ¡ì‹œì„¤: {len(df_gym)}ê°œ ë¡œë“œ")
    except: debug_info.append("âŒ ì²´ìœ¡ì‹œì„¤ íŒŒì¼ ì—†ìŒ/ì˜¤ë¥˜")

    if not all_data: return pd.DataFrame(), debug_info
    return pd.concat(all_data, ignore_index=True), debug_info

def haversine(lat1, lon1, lat2, lon2):
    R = 6371.0
    lat1_rad, lon1_rad = np.radians(lat1), np.radians(lon1)
    lat2_rad, lon2_rad = np.radians(lat2), np.radians(lon2)
    dlon = lon2_rad - lon1_rad
    dlat = lat2_rad - lat1_rad
    a = np.sin(dlat / 2)**2 + np.cos(lat1_rad) * np.cos(lat2_rad) * np.sin(dlon / 2)**2
    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))
    return R * c * 1000.0

@st.cache_data(show_spinner="í•„í„°ë§ ë¡œì§ ì‹¤í–‰ ì¤‘...")
def filter_apartments(df_apt, df_infra, selected_filters):
    if df_apt is None or df_apt.empty or not selected_filters:
        return pd.DataFrame()

    filtered_apt_list = []
    
    # ì¸í”„ë¼ ë°ì´í„° ë¯¸ë¦¬ í•„í„°ë§ (ì†ë„ ìµœì í™”)
    infra_dict = {}
    for infra_type in selected_filters.keys():
        infra_dict[infra_type] = df_infra[df_infra['type'] == infra_type].copy()

    for index, apt in df_apt.iterrows():
        apt_lat = apt['lat']
        apt_lng = apt['lng']
        
        meets_all_criteria = True
        individual_counts = {f'{t}_ì¹´ìš´íŠ¸': 0 for t in selected_filters.keys()}

        for infra_type, radius_m in selected_filters.items():
            infra_of_type = infra_dict[infra_type]
            if infra_of_type.empty:
                meets_all_criteria = False; break

            distances = haversine(apt_lat, apt_lng, infra_of_type['lat'].values, infra_of_type['lng'].values)
            
            # í•˜ë‚˜ë¼ë„ ë°˜ê²½ ë‚´ì— ì—†ìœ¼ë©´ íƒˆë½ (AND ì¡°ê±´)
            if np.min(distances) > radius_m:
                meets_all_criteria = False; break

            count_type = np.sum(distances <= radius_m)
            individual_counts[infra_type + '_ì¹´ìš´íŠ¸'] = int(count_type)

        if meets_all_criteria:
            apt_data = apt.to_dict() # ì—¬ê¸°ì„œ ì›ë³¸ ì»¬ëŸ¼(ì£¼ì†Œ í¬í•¨)ì´ ë‹¤ ë“¤ì–´ê°
            apt_data.update(individual_counts)
            if 'ìì¹˜êµ¬ëª…' not in apt_data: apt_data['ìì¹˜êµ¬ëª…'] = ''
            filtered_apt_list.append(apt_data)

    df_filtered_apt = pd.DataFrame(filtered_apt_list)
    
    if df_filtered_apt.empty:
        return pd.DataFrame()

    count_cols = [col for col in df_filtered_apt.columns if col.endswith('_ì¹´ìš´íŠ¸')]
    df_filtered_apt['Total_Count'] = df_filtered_apt[count_cols].sum(axis=1)
        
    return df_filtered_apt.sort_values(by='Total_Count', ascending=False).drop(columns=['Total_Count']).copy()

def get_apartment_infrastructure_details(apt_data, df_infra, selected_filters):
    apt_lat = apt_data['latitude']
    apt_lng = apt_data['longitude']
    details_list = []
    
    for infra_type, radius_m in selected_filters.items():
        infra_of_type = df_infra[df_infra['type'] == infra_type]
        for idx, item in infra_of_type.iterrows():
            distance = haversine(apt_lat, apt_lng, item['lat'], item['lng'])
            if distance <= radius_m:
                details_list.append({
                    'ì¸í”„ë¼_ìœ í˜•': infra_type,
                    'ì‹œì„¤ëª…': item['infra_name'],
                    'ê±°ë¦¬(m)': int(round(distance)),
                    'lat': item['lat'],  
                    'lng': item['lng']    
                })
    return pd.DataFrame(details_list).sort_values(by='ê±°ë¦¬(m)')

# ====================================================================
# --- 2. ì§€ë„ ìƒì„± í•¨ìˆ˜ ---
# ====================================================================

def create_folium_map(df_map, df_infra, selected_filters):
    center_lat = df_map['latitude'].mean()
    center_lng = df_map['longitude'].mean()

    m = folium.Map(location=[center_lat, center_lng], zoom_start=12, tiles='https://xdworld.vworld.kr/2d/Base/service/{z}/{x}/{y}.png', attr='Vworld')
    
    colors = {'ì´ˆë“±í•™êµ': 'blue', 'ì¤‘í•™êµ': 'green', 'ê³ ë“±í•™êµ': 'orange', 'ë¬¸í™”ì‹œì„¤': 'purple', 'ê³µì›': 'darkgreen', 'ëŒ€í˜•ë³‘ì›': 'red', 'ì¼ë°˜ë³‘ì›': 'lightred', 'ë²„ìŠ¤ì •ë¥˜ì¥': 'cadetblue', 'ì§€í•˜ì² ì—­': 'darkblue', 'ëŒ€í˜•ë§ˆíŠ¸': 'pink', 'ë°±í™”ì ': 'beige', 'ìˆ˜ì˜ì¥': 'lightblue', 'ìƒí™œì²´ìœ¡ê´€': 'lightgreen', 'ì¶•êµ¬ì¥': 'lightgreen', 'ì•¼êµ¬ì¥': 'orange', 'ë†êµ¬ì¥': 'orange', 'í…Œë‹ˆìŠ¤ì¥': 'lightgreen', 'ë°°ë“œë¯¼í„´ì¥': 'cadetblue', 'ê³¨í”„ì—°ìŠµì¥': 'green', 'ê¸°íƒ€': 'gray'}
    icons = {'ì´ˆë“±í•™êµ': 'graduation-cap', 'ì¤‘í•™êµ': 'university', 'ê³ ë“±í•™êµ': 'landmark', 'ë¬¸í™”ì‹œì„¤': 'palette', 'ê³µì›': 'tree', 'ëŒ€í˜•ë³‘ì›': 'ambulance', 'ì¼ë°˜ë³‘ì›': 'plus-square', 'ë²„ìŠ¤ì •ë¥˜ì¥': 'bus', 'ì§€í•˜ì² ì—­': 'subway', 'ëŒ€í˜•ë§ˆíŠ¸': 'shopping-cart', 'ë°±í™”ì ': 'gift', 'ìˆ˜ì˜ì¥': 'person-swimming', 'ìƒí™œì²´ìœ¡ê´€': 'dumbbell', 'ì¶•êµ¬ì¥': 'futbol', 'ì•¼êµ¬ì¥': 'baseball-bat-ball', 'ë†êµ¬ì¥': 'basketball', 'í…Œë‹ˆìŠ¤ì¥': 'table-tennis-paddle-ball', 'ë°°ë“œë¯¼í„´ì¥': 'feather', 'ê³¨í”„ì—°ìŠµì¥': 'golf-ball-tee', 'ê¸°íƒ€': 'star'}
    
    relevant_infra_list = []
    # ì¸í”„ë¼ ë§ˆì»¤ ì¶”ê°€ ë¡œì§
    for infra_type, radius_m in selected_filters.items():
        infra_of_type = df_infra[df_infra['type'] == infra_type].copy()
        # ë²¡í„°í™” ì—°ì‚°ìœ¼ë¡œ ê±°ë¦¬ ê³„ì‚° ìµœì í™” ê°€ëŠ¥í•˜ë‚˜ ì—¬ê¸°ì„  ìˆœíšŒ ìœ ì§€
        for idx, item in infra_of_type.iterrows():
            distances = haversine(item['lat'], item['lng'], df_map['latitude'].values, df_map['longitude'].values)
            if np.min(distances) <= radius_m:
                 relevant_infra_list.append(item.to_dict())

    df_relevant_infra = pd.DataFrame(relevant_infra_list).drop_duplicates(subset=['infra_name', 'lat', 'lng'])

    if not df_relevant_infra.empty:
        infra_group = folium.FeatureGroup(name="ë°œê²¬ëœ ì¸í”„ë¼", show=True).add_to(m)
        for idx, item in df_relevant_infra.iterrows():
            folium.Marker(
                location=[item['lat'], item['lng']],
                popup=f"{item['infra_name']}",
                icon=folium.Icon(color=colors.get(item['type'], 'gray'), icon=icons.get(item['type'], 'star'), prefix='fa')
            ).add_to(infra_group)

    # ì•„íŒŒíŠ¸ ë§ˆì»¤
    apt_group = folium.FeatureGroup(name="í•„í„°ë§ëœ ì•„íŒŒíŠ¸", show=True).add_to(m)
    for idx, apt in df_map.iterrows():
        folium.Marker(
            location=[apt['latitude'], apt['longitude']],
            popup=f"{apt['ìì¹˜êµ¬ëª…']} {apt['ê±´ë¬¼ëª…']}",
            icon=folium.Icon(color='darkpurple', icon='home', prefix='fa')
        ).add_to(apt_group)
        
    folium.LayerControl(collapsed=True).add_to(m)
    return components.html(m.get_root().render(), height=740, scrolling=True)

def create_detailed_map(apt_data, df_details):
    center_lat = apt_data['latitude']
    center_lng = apt_data['longitude']
    m = folium.Map(location=[center_lat, center_lng], zoom_start=14, tiles='https://xdworld.vworld.kr/2d/Base/service/{z}/{x}/{y}.png', attr='Vworld')
    
    # ì•„íŒŒíŠ¸ ë§ˆì»¤
    folium.Marker(
        location=[center_lat, center_lng],
        popup=f"ì„ íƒ: {apt_data['ìì¹˜êµ¬ëª…']} {apt_data['ê±´ë¬¼ëª…']}",
        icon=folium.Icon(color='black', icon='building', prefix='fa')
    ).add_to(m)
    
    colors = {'ì´ˆë“±í•™êµ': 'blue', 'ì¤‘í•™êµ': 'green', 'ê³ ë“±í•™êµ': 'orange', 'ë¬¸í™”ì‹œì„¤': 'purple', 'ê³µì›': 'darkgreen', 'ëŒ€í˜•ë³‘ì›': 'red', 'ì¼ë°˜ë³‘ì›': 'lightred', 'ë²„ìŠ¤ì •ë¥˜ì¥': 'cadetblue', 'ì§€í•˜ì² ì—­': 'darkblue', 'ëŒ€í˜•ë§ˆíŠ¸': 'pink', 'ë°±í™”ì ': 'beige', 'ìˆ˜ì˜ì¥': 'lightblue', 'ìƒí™œì²´ìœ¡ê´€': 'lightgreen', 'ì¶•êµ¬ì¥': 'lightgreen', 'ì•¼êµ¬ì¥': 'orange', 'ë†êµ¬ì¥': 'orange', 'í…Œë‹ˆìŠ¤ì¥': 'lightgreen', 'ë°°ë“œë¯¼í„´ì¥': 'cadetblue', 'ê³¨í”„ì—°ìŠµì¥': 'green', 'ê¸°íƒ€': 'gray'}
    icons = {'ì´ˆë“±í•™êµ': 'graduation-cap', 'ì¤‘í•™êµ': 'university', 'ê³ ë“±í•™êµ': 'landmark', 'ë¬¸í™”ì‹œì„¤': 'palette', 'ê³µì›': 'tree', 'ëŒ€í˜•ë³‘ì›': 'ambulance', 'ì¼ë°˜ë³‘ì›': 'plus-square', 'ë²„ìŠ¤ì •ë¥˜ì¥': 'bus', 'ì§€í•˜ì² ì—­': 'subway', 'ëŒ€í˜•ë§ˆíŠ¸': 'shopping-cart', 'ë°±í™”ì ': 'gift', 'ìˆ˜ì˜ì¥': 'person-swimming', 'ìƒí™œì²´ìœ¡ê´€': 'dumbbell', 'ì¶•êµ¬ì¥': 'futbol', 'ì•¼êµ¬ì¥': 'baseball-bat-ball', 'ë†êµ¬ì¥': 'basketball', 'í…Œë‹ˆìŠ¤ì¥': 'table-tennis-paddle-ball', 'ë°°ë“œë¯¼í„´ì¥': 'feather', 'ê³¨í”„ì—°ìŠµì¥': 'golf-ball-tee', 'ê¸°íƒ€': 'star'}

    for idx, item in df_details.iterrows():
        itype = item['ì¸í”„ë¼_ìœ í˜•']
        folium.Marker(
            location=[item['lat'], item['lng']],
            popup=f"{item['ì‹œì„¤ëª…']} ({item['ê±°ë¦¬(m)']}m)",
            icon=folium.Icon(color=colors.get(itype,'gray'), icon=icons.get(itype,'star'), prefix='fa')
        ).add_to(m)
        folium.PolyLine(
            locations=[(center_lat, center_lng), (item['lat'], item['lng'])],
            color=colors.get(itype,'gray'), weight=2, opacity=0.7
        ).add_to(m)

    return components.html(m.get_root().render(), height=740, scrolling=True)

# ====================================================================
# --- 3. Streamlit ì• í”Œë¦¬ì¼€ì´ì…˜ ë©”ì¸ í•¨ìˆ˜ ---
# ====================================================================

def main():
    st.set_page_config(layout="wide")
    
    # CSS ìŠ¤íƒ€ì¼ë§
    st.markdown("""
    <style>
    .metric-container { display: flex; justify-content: center; align-items: center; padding: 8px; background-color: #f8f9fa; border-radius: 8px; margin-bottom: 8px; border: 1px solid #e0e0e0; min-width: 100px; }
    .metric-box { text-align: center; width: 100%; }
    .metric-label { font-size: 1.0rem; font-weight: 700; color: #31333F; margin-bottom: 2px; white-space: nowrap; }
    .metric-value { font-size: 0.9rem; color: #555; }
    </style>
    """, unsafe_allow_html=True)

    st.title("ğŸ¡ ì¸í”„ë¼ ì ‘ê·¼ì„± ë¶„ì„ ëŒ€ì‹œë³´ë“œ")
    st.markdown("---")

    df_infra, debug_info = load_all_infrastructure_data()
    
    # [ì‚¬ì´ë“œë°”]
    st.sidebar.markdown("### ğŸ¢ ì•„íŒŒíŠ¸ ë°ì´í„° ì—…ë¡œë“œ")
    with st.sidebar.container(border=True):
        uploaded_file = st.file_uploader("", type="csv", label_visibility="hidden")
    
    df_apt = None
    if uploaded_file is not None:
        try:
            df_apt_temp = pd.read_csv(uploaded_file)
            # [ìˆ˜ì •] ì¡°ì¸ Keyë¡œ ì‚¬ìš©í•  'ì£¼ì†Œ' ì»¬ëŸ¼ í•„ìˆ˜ í™•ì¸
            required_cols = ['ìì¹˜êµ¬ëª…', 'ì£¼ì†Œ', 'ê±´ë¬¼ëª…', 'lat', 'lng']
            if not all(col in df_apt_temp.columns for col in required_cols):
                st.sidebar.error(f"âŒ í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½! CSV íŒŒì¼ì— ë‹¤ìŒ ì»¬ëŸ¼ì´ ëª¨ë‘ ìˆì–´ì•¼ í•©ë‹ˆë‹¤:\n{', '.join(required_cols)}")
            else:
                st.sidebar.success(f"âœ… **{uploaded_file.name}** ë°ì´í„° ë¡œë“œ ì™„ë£Œ.")
                df_apt = df_apt_temp.copy()
        except Exception as e:
            st.sidebar.error(f"âŒ íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            df_apt = None
    else:
        st.sidebar.info("ì—…ë¡œë“œí•  CSV íŒŒì¼ì„ ì„ íƒí•˜ê±°ë‚˜ ë“œë˜ê·¸ ì•¤ ë“œë¡­í•˜ì„¸ìš”.")

    st.sidebar.markdown("<br>", unsafe_allow_html=True)
    
    # [ì‚¬ì´ë“œë°”] ì¸í”„ë¼ í•„í„° ì„¤ì •
    st.sidebar.markdown("### ğŸ›ï¸ ì¸í”„ë¼ í•„í„° ì„¤ì •")
    selected_filters = {}
    max_radius = 5000

    with st.sidebar.container(border=True):
        # í•™êµ
        st.markdown("#### ğŸ« í•™êµ ì‹œì„¤")
        if st.checkbox("ì´ˆë“±í•™êµ", value=False): selected_filters['ì´ˆë“±í•™êµ'] = st.slider("ì´ˆë“±í•™êµ (m)", 100, max_radius, 500, 50, key="s_elem")
        if st.checkbox("ì¤‘í•™êµ", value=False): selected_filters['ì¤‘í•™êµ'] = st.slider("ì¤‘í•™êµ (m)", 100, max_radius, 1000, 50, key="s_mid")
        if st.checkbox("ê³ ë“±í•™êµ", value=False): selected_filters['ê³ ë“±í•™êµ'] = st.slider("ê³ ë“±í•™êµ (m)", 100, max_radius, 1500, 50, key="s_high")
        st.markdown("<br>", unsafe_allow_html=True)
        # ë³‘ì›
        st.markdown("#### ğŸ¥ ë³‘ì› ì‹œì„¤")
        if st.checkbox("ëŒ€í˜•ë³‘ì›", value=False): selected_filters['ëŒ€í˜•ë³‘ì›'] = st.slider("ëŒ€í˜•ë³‘ì› (m)", 100, max_radius, 1500, 50, key="s_er")
        if st.checkbox("ì¼ë°˜ë³‘ì›", value=False): selected_filters['ì¼ë°˜ë³‘ì›'] = st.slider("ì¼ë°˜ë³‘ì› (m)", 100, max_radius, 1000, 50, key="s_gen")
        st.markdown("<br>", unsafe_allow_html=True)
        # êµí†µ
        st.markdown("#### ğŸš— êµí†µ ì‹œì„¤")
        if st.checkbox("ë²„ìŠ¤ì •ë¥˜ì¥", value=False): selected_filters['ë²„ìŠ¤ì •ë¥˜ì¥'] = st.slider("ë²„ìŠ¤ì •ë¥˜ì¥ (m)", 100, max_radius, 500, 50, key="s_bus")
        if st.checkbox("ì§€í•˜ì² ì—­", value=False): selected_filters['ì§€í•˜ì² ì—­'] = st.slider("ì§€í•˜ì² ì—­ (m)", 100, max_radius, 1000, 50, key="s_sub")
        st.markdown("<br>", unsafe_allow_html=True)
        # í¸ì˜
        st.markdown("#### ğŸ›’ ìƒí™œ í¸ì˜")
        if st.checkbox("ëŒ€í˜•ë§ˆíŠ¸", value=False): selected_filters['ëŒ€í˜•ë§ˆíŠ¸'] = st.slider("ëŒ€í˜•ë§ˆíŠ¸ (m)", 100, max_radius, 2000, 50, key="s_mart")
        if st.checkbox("ë°±í™”ì ", value=False): selected_filters['ë°±í™”ì '] = st.slider("ë°±í™”ì  (m)", 100, max_radius, 3000, 50, key="s_dept")
        st.markdown("<br>", unsafe_allow_html=True)
        # ë¬¸í™”
        st.markdown("#### ğŸ¨ ë¬¸í™”/ì—¬ê°€")
        if st.checkbox("ê³µì›", value=False): selected_filters['ê³µì›'] = st.slider("ê³µì› (m)", 100, max_radius, 1000, 50, key="s_park")
        if st.checkbox("ë¬¸í™”ì‹œì„¤", value=False): selected_filters['ë¬¸í™”ì‹œì„¤'] = st.slider("ë¬¸í™”ì‹œì„¤ (m)", 100, max_radius, 2000, 50, key="s_art")
        st.markdown("<br>", unsafe_allow_html=True)

    if df_apt is None:
        st.info("ğŸ‘‹ **í™˜ì˜í•©ë‹ˆë‹¤!** ë¶„ì„ì„ ì‹œì‘í•˜ë ¤ë©´ **ì™¼ìª½ ì‚¬ì´ë“œë°”**ì—ì„œ ì•„íŒŒíŠ¸ ë°ì´í„° íŒŒì¼(CSV)ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
        return
        
    if not selected_filters:
        st.warning("ğŸ‘ˆ **ì•ˆë‚´:** ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ ë¶„ì„í•  **ì¸í”„ë¼ ì¢…ë¥˜ë¥¼ í•˜ë‚˜ ì´ìƒ ì²´í¬**í•´ ì£¼ì„¸ìš”.")
        return

    # íƒœê·¸ í‘œì‹œ
    with st.container(border=True):
        st.markdown("### ğŸ” í•„í„°ë§ ê¸°ì¤€")
        icon_map_filter = {'ì´ˆë“±í•™êµ':'ğŸ’', 'ì¤‘í•™êµ':'ğŸ“š', 'ê³ ë“±í•™êµ':'ğŸ›ï¸', 'ë¬¸í™”ì‹œì„¤':'ğŸ¨', 'ê³µì›':'ğŸŒ³', 'ëŒ€í˜•ë³‘ì›':'ğŸš‘', 'ì¼ë°˜ë³‘ì›':'ğŸ¥', 'ë²„ìŠ¤ì •ë¥˜ì¥':'ğŸšŒ', 'ì§€í•˜ì² ì—­':'ğŸš‡', 'ëŒ€í˜•ë§ˆíŠ¸':'ğŸ›’', 'ë°±í™”ì ':'ğŸ›ï¸'}
        tags_html = """<div style="display: flex; flex-direction: row; flex-wrap: wrap; gap: 8px; align-items: center; width: 100%; margin-bottom: 24px;">"""
        for key, radius in selected_filters.items():
            icon = icon_map_filter.get(key, 'ğŸ“')
            tags_html += f"""<div style="display: inline-flex; align-items: center; background-color: #f0f2f6; border: 1px solid #d1d5db; border-radius: 20px; padding: 6px 12px; color: #31333F; font-size: 14px; font-weight: 500; white-space: nowrap; box-shadow: 0 1px 2px rgba(0,0,0,0.05);"><span style="margin-right: 6px; font-size: 16px;">{icon}</span>{key} <span style="color: #666; font-size: 12px; margin-left: 6px; font-weight: 400;">{radius}m</span></div>"""
        tags_html += "</div>"
        st.markdown(tags_html, unsafe_allow_html=True)
    
    # ---------------------------------------------------------
    # í•„í„°ë§ ì‹¤í–‰
    # ---------------------------------------------------------
    df_filtered = filter_apartments(df_apt, df_infra, selected_filters)
    
    if df_filtered.empty:
        st.warning("ì„ íƒëœ ì¡°ê±´(ê±°ë¦¬/ì¸í”„ë¼ ì¢…ë¥˜)ì— í•´ë‹¹í•˜ëŠ” ì•„íŒŒíŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # [ìˆ˜ì •] ì§€ë„ ë° í™”ë©´ í‘œì‹œìš©ìœ¼ë¡œ ì´ë¦„ ë³€ê²½ (lat, lng -> latitude, longitude)
    df_map = df_filtered.rename(columns={'lat': 'latitude', 'lng': 'longitude'})
    df_map['display_name'] = "[" + df_map['ìì¹˜êµ¬ëª…'] + "] " + df_map['ê±´ë¬¼ëª…']
    
    apartment_names = ['--- ì „ì²´ ìš”ì•½ ë³´ê¸° ---'] + df_map['display_name'].tolist()
    
    head_col1, head_col2 = st.columns(2)
    with head_col1: header_left_placeholder = st.empty()
    with head_col2: header_right_placeholder = st.empty()
    
    body_col1, body_col2 = st.columns(2)
    
    with body_col2:
        with st.container(border=True):
            st.markdown("##### ğŸ“ ë§¤ë¬¼ ì„ íƒ")
            selected_name_display = st.selectbox("ë§¤ë¬¼ ì„ íƒ", apartment_names, key='drill_down_select', label_visibility='collapsed')
        summary_placeholder = st.empty()
        table_container = st.container(border=True)

    if selected_name_display == '--- ì „ì²´ ìš”ì•½ ë³´ê¸° ---':
        # [A] ì „ì²´ ìš”ì•½ ëª¨ë“œ
        with header_left_placeholder.container():
            with st.container(border=True):
                st.markdown(f"#### âœ… ìµœì¢… ê²€ìƒ‰ ê²°ê³¼: ì´ **{len(df_filtered)}** ê°œì˜ ë§¤ë¬¼")
        
        with header_right_placeholder.container():
            with st.container(border=True):
                st.markdown("#### ğŸ¢ ì•„íŒŒíŠ¸ ì¶”ì²œ ëª©ë¡")
        
        with body_col1:
            create_folium_map(df_map, df_infra, selected_filters)
            
        with table_container:
            st.markdown("##### ğŸ“‹ ì•„íŒŒíŠ¸ ìƒì„¸ ëª©ë¡")
            
            # [ìˆ˜ì •] 'ì£¼ì†Œ' ì»¬ëŸ¼ì„ display_colsì— í¬í•¨ì‹œí‚´ (ë‚˜ì¤‘ì— Exportë¥¼ ìœ„í•´)
            display_cols = ['ìì¹˜êµ¬ëª…', 'ì£¼ì†Œ', 'ê±´ë¬¼ëª…'] + [f'{k}_ì¹´ìš´íŠ¸' for k in selected_filters.keys()]
            rename_map = {f'{k}_ì¹´ìš´íŠ¸': k for k in selected_filters.keys()}
            
            # [ìˆ˜ì •] column_configë¥¼ ì‚¬ìš©í•˜ì—¬ 'ì£¼ì†Œ', 'lat', 'lng' ë“±ì„ í™”ë©´ì—ì„œë§Œ ìˆ¨ê¹€
            st.dataframe(
                df_map[display_cols].rename(columns=rename_map),
                use_container_width=True, 
                hide_index=True,
                column_config={
                    "ì£¼ì†Œ": None,  # <--- í™”ë©´ì—ì„œ ìˆ¨ê¹€ (ë°ì´í„°ëŠ” ì¡´ì¬í•¨)
                }
            )

            # [ì¶”ê°€] ë‹¤ìš´ë¡œë“œ ë²„íŠ¼: í™”ë©´ì—” ì•ˆ ë³´ì˜€ë˜ 'ì£¼ì†Œ'ê°€ í¬í•¨ëœ CSVë¥¼ ë‚´ë ¤ë°›ìŒ
            csv_data = df_map[display_cols].rename(columns=rename_map).to_csv(index=False).encode('utf-8-sig')
            
            st.download_button(
                label="ğŸ“¥ ë¦¬ìŠ¤íŠ¸ ë‹¤ìš´ë¡œë“œ (ì£¼ì†Œ í¬í•¨)",
                data=csv_data,
                file_name='filtered_apartments_result.csv',
                mime='text/csv',
                help="ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ì—ëŠ” ë¶„ì„ìš© ì¡°ì¸ì„ ìœ„í•œ 'ì£¼ì†Œ' ì»¬ëŸ¼ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤."
            )

    else:
        # [B] ìƒì„¸ ë¶„ì„ ëª¨ë“œ
        selected_apt_row = df_map[df_map['display_name'] == selected_name_display].iloc[0]
        
        apt_data_for_detail = {
            'latitude': selected_apt_row['latitude'], 
            'longitude': selected_apt_row['longitude'], 
            'ê±´ë¬¼ëª…': selected_apt_row['ê±´ë¬¼ëª…'],
            'ìì¹˜êµ¬ëª…': selected_apt_row['ìì¹˜êµ¬ëª…']
        }
        df_details = get_apartment_infrastructure_details(apt_data_for_detail, df_infra, selected_filters)
        
        selected_apt_total_count = df_details.shape[0]
        
        with header_left_placeholder.container():
            with st.container(border=True):
                st.markdown(f"#### âœ… **{selected_name_display}** ì£¼ë³€ ì¸í”„ë¼ : ì´ **{selected_apt_total_count}**ê°œ")
        
        with header_right_placeholder.container():
            with st.container(border=True):
                st.markdown(f"#### ğŸ¢ {selected_name_display} ì£¼ë³€ ì¸í”„ë¼ ëª©ë¡")
        
        with body_col1:
            create_detailed_map(apt_data_for_detail, df_details)
            
        with summary_placeholder.container():
            with st.container(border=True):
                st.markdown("##### ğŸ“Š ì¸í”„ë¼ ìš”ì•½")
                # (ê¸°ì¡´ ìš”ì•½ ë¡œì§ ìœ ì§€)
                infra_counts = df_details['ì¸í”„ë¼_ìœ í˜•'].value_counts()
                filter_keys = list(selected_filters.keys())
                for i in range(0, len(filter_keys), 3):
                    cols = st.columns(3)
                    chunk = filter_keys[i:i+3]
                    for j, key in enumerate(chunk):
                        with cols[j]:
                            count = infra_counts.get(key, 0)
                            icon_map = {'ì´ˆë“±í•™êµ':'ğŸ’', 'ì¤‘í•™êµ':'ğŸ“š', 'ê³ ë“±í•™êµ':'ğŸ›ï¸', 'ë¬¸í™”ì‹œì„¤':'ğŸ¨', 'ê³µì›':'ğŸŒ³', 'ëŒ€í˜•ë³‘ì›':'ğŸš‘', 'ì¼ë°˜ë³‘ì›':'ğŸ¥', 'ë²„ìŠ¤ì •ë¥˜ì¥':'ğŸšŒ', 'ì§€í•˜ì² ì—­':'ğŸš‡', 'ëŒ€í˜•ë§ˆíŠ¸':'ğŸ›’', 'ë°±í™”ì ':'ğŸ›ï¸'}
                            label = f"{icon_map.get(key, '')} {key}"
                            st.markdown(f"""<div class="metric-container"><div class="metric-box"><div class="metric-label">{label}</div><div class="metric-value">{count}ê°œ</div></div></div>""", unsafe_allow_html=True)
        
        with table_container:
            st.markdown("##### ğŸ“‹ ì¸í”„ë¼ ìƒì„¸ ëª©ë¡")
            if not df_details.empty:
                st.dataframe(df_details[['ì¸í”„ë¼_ìœ í˜•', 'ì‹œì„¤ëª…', 'ê±°ë¦¬(m)']], use_container_width=True, hide_index=True)
            else:
                st.info("ì„ íƒëœ ë°˜ê²½ ë‚´ì— í•´ë‹¹ ì¸í”„ë¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()
